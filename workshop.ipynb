{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9d359c",
   "metadata": {},
   "source": [
    "## Preflight Check\n",
    "\n",
    "If this fails with 401, regenerate OpenRouter key and restart kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bc0d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL WORKING\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=False)\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"].strip(),\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8888\",\n",
    "        \"X-Title\": \"Dallas Agent Workshop\",\n",
    "    },\n",
    ")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=os.getenv(\"OPENROUTER_MODEL\", \"arcee-ai/trinity-large-preview:free\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Reply with exactly: MODEL WORKING\"}],\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef53b8",
   "metadata": {},
   "source": [
    "# Dallas AI ‚Äî Hands-on Agent Building (LangGraph + OpenRouter)\n",
    "\n",
    "This notebook is the main workshop surface:\n",
    "- You will run the agent locally.\n",
    "- The model is accessed via OpenRouter.\n",
    "- The agent can generate Python code and execute it using a controlled tool.\n",
    "\n",
    "**Goal:** experience a real *plan ‚Üí code ‚Üí execute ‚Üí fix* loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951d183",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "1. Create a venv and install deps:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "2. Copy `.env.example` to `.env` and set `OPENROUTER_API_KEY`.\n",
    "3. Restart kernel after editing `.env`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3898aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repr: 'e000c20e40'\n",
      "endswith newline? False\n",
      "has spaces? False\n",
      "len raw: 73 len strip: 73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENROUTER_MODEL\"] = \"arcee-ai/trinity-large-preview:free\"\n",
    "\n",
    "k = os.environ[\"OPENROUTER_API_KEY\"]\n",
    "print(\"repr:\", repr(k[-10:]))\n",
    "print(\"endswith newline?\", k.endswith(\"\\n\"))\n",
    "print(\"has spaces?\", (\" \" in k))\n",
    "print(\"len raw:\", len(k), \"len strip:\", len(k.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a3afab-4035-4279-871a-37ef4a0c687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"data\":[{\"id\":\"anthropic/claude-sonnet-4.6\",\"canonical_slug\":\"anthropic/claude-4.6-sonnet-20260217\",\"hugging_face_id\":\"\",\"name\":\"Anthropic: Claude Sonnet 4.6\",\"created\":1771342990,\"description\":\"Sonnet 4.6 is Anthropic's most capable Sonnet-class model yet, with frontier performance across coding, \n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "headers = {\"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY'].strip()}\"}\n",
    "r = requests.get(\"https://openrouter.ai/api/v1/models\", headers=headers, timeout=20)\n",
    "print(r.status_code)\n",
    "print(r.text[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac4256",
   "metadata": {},
   "source": [
    "## 1) Sanity check: run the Python execution tool\n",
    "\n",
    "This runs locally with timeouts and basic restrictions. It is **not** a hardened sandbox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6994df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'stdout': 'hello from tool\\n6\\n',\n",
       " 'stderr': '',\n",
       " 'exit_code': 0,\n",
       " 'note': 'Execution policy: temporary working directory, time-limited, and blocks some risky imports/calls. This is NOT a hardened sandbox.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import run_python\n",
    "\n",
    "code = \"\"\"\n",
    "print('hello from tool')\n",
    "print(sum([1,2,3]))\n",
    "\"\"\"\n",
    "\n",
    "run_python(code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314648a",
   "metadata": {},
   "source": [
    "## 2) Run a single agent task\n",
    "\n",
    "We will run one end-to-end task:\n",
    "- Planner proposes solution + code\n",
    "- Executor runs code\n",
    "- If fails, Fixer patches and retries (up to 3 attempts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e549b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATED CODE ===\n",
      "def fibonacci(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    a, b = 0, 1\n",
      "    for _ in range(2, n + 1):\n",
      "        a, b = b, a + b\n",
      "    return b\n",
      "\n",
      "print(fibonacci(35))\n",
      "======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'stdout': '9227465\\n',\n",
       " 'stderr': '',\n",
       " 'exit_code': 0,\n",
       " 'note': 'Execution policy: temporary working directory, time-limited, and blocks some risky imports/calls. This is NOT a hardened sandbox.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent_lib import run_task\n",
    "\n",
    "task = \"Write a Python function to compute Fibonacci(n) efficiently and print Fibonacci(35).\"\n",
    "result = run_task(task)\n",
    "\n",
    "result['last_run']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a672d9",
   "metadata": {},
   "source": [
    "## 3) Workshop exercises\n",
    "\n",
    "Try the tasks below. You can also author your own.\n",
    "Tip: keep tasks self-contained and offline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25ceab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK: Parse this CSV string and compute the average of the 'latency_ms' column:\n",
      "\n",
      "ts,latency_ms\n",
      "1,120\n",
      "2,110\n",
      "3,130\n",
      "4,90\n",
      "\n",
      "=== GENERATED CODE ===\n",
      "import csv\n",
      "from io import StringIO\n",
      "\n",
      "csv_string = \"\"\"ts,latency_ms\n",
      "1,120\n",
      "2,110\n",
      "3,130\n",
      "4,90\"\"\"\n",
      "\n",
      "f = StringIO(csv_string)\n",
      "reader = csv.DictReader(f)\n",
      "latencies = [int(row['latency_ms']) for row in reader]\n",
      "average_latency = sum(latencies) / len(latencies)\n",
      "print(average_latency)\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " 112.5\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TASK: Implement rolling z-score anomaly score for this list and print the top 3 most anomalous points: [10,11,9,10,10,200,11,10,9,10]\n",
      "=== GENERATED CODE ===\n",
      "import numpy as np\n",
      "\n",
      "data = [10, 11, 9, 10, 10, 200, 11, 10, 9, 10]\n",
      "window_size = 3\n",
      "z_scores = []\n",
      "\n",
      "for i in range(len(data)):\n",
      "    if i < window_size - 1:\n",
      "        z_scores.append(0)\n",
      "    else:\n",
      "        window = data[i - window_size + 1:i + 1]\n",
      "        mean = np.mean(window)\n",
      "        std = np.std(window)\n",
      "        if std == 0:\n",
      "            z = 0\n",
      "        else:\n",
      "            z = (data[i] - mean) / std\n",
      "        z_scores.append(z)\n",
      "\n",
      "# Find top 3 most anomalous points (highest absolute z-scores)\n",
      "anomalies = sorted(\n",
      "    [(i, data[i], abs(z_scores[i])) for i in range(len(data))],\n",
      "    key=lambda x: x[2],\n",
      "    reverse=True\n",
      ")[:3]\n",
      "\n",
      "print(\"Top 3 most anomalous points:\")\n",
      "for idx, value, score in anomalies:\n",
      "    print(f\"Index {idx}: value={value}, z-score={z_scores[idx]:.2f}\")\n",
      "======================\n",
      "=== GENERATED CODE ===\n",
      "data = [10, 11, 9, 10, 10, 200, 11, 10, 9, 10]\n",
      "window_size = 3\n",
      "z_scores = []\n",
      "\n",
      "for i in range(len(data)):\n",
      "    if i < window_size - 1:\n",
      "        z_scores.append(0)\n",
      "    else:\n",
      "        window = data[i - window_size + 1:i + 1]\n",
      "        mean = sum(window) / len(window)\n",
      "        variance = sum((x - mean) ** 2 for x in window) / len(window)\n",
      "        std = variance ** 0.5\n",
      "        if std == 0:\n",
      "            z = 0\n",
      "        else:\n",
      "            z = (data[i] - mean) / std\n",
      "        z_scores.append(z)\n",
      "\n",
      "# Find top 3 most anomalous points (highest absolute z-scores)\n",
      "anomalies = sorted(\n",
      "    [(i, data[i], abs(z_scores[i])) for i in range(len(data))],\n",
      "    key=lambda x: x[2],\n",
      "    reverse=True\n",
      ")[:3]\n",
      "\n",
      "print(\"Top 3 most anomalous points:\")\n",
      "for idx, value, score in anomalies:\n",
      "    print(f\"Index {idx}: value={value}, z-score={z_scores[idx]:.2f}\")\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " Top 3 most anomalous points:\n",
      "Index 5: value=200, z-score=1.41\n",
      "Index 2: value=9, z-score=-1.22\n",
      "Index 8: value=9, z-score=-1.22\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TASK: Given a list of (user_id, event_time, event_type), compute per-user session counts (30-min gap) and print a dict.\n",
      "=== GENERATED CODE ===\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "events = [\n",
      "    (1, '2023-10-01 10:00:00', 'click'),\n",
      "    (1, '2023-10-01 10:15:00', 'view'),\n",
      "    (1, '2023-10-01 10:45:00', 'click'),\n",
      "    (2, '2023-10-01 11:00:00', 'click'),\n",
      "    (2, '2023-10-01 11:20:00', 'view'),\n",
      "    (2, '2023-10-01 11:50:00', 'click'),\n",
      "]\n",
      "\n",
      "# Convert event_time strings to datetime objects\n",
      "for i in range(len(events)):\n",
      "    user_id, event_time, event_type = events[i]\n",
      "    events[i] = (user_id, datetime.strptime(event_time, '%Y-%m-%d %H:%M:%S'), event_type)\n",
      "\n",
      "# Sort events by user_id and event_time\n",
      "events.sort(key=lambda x: (x[0], x[1]))\n",
      "\n",
      "# Compute sessions per user\n",
      "sessions = {}\n",
      "current_user = None\n",
      "session_start = None\n",
      "\n",
      "for user_id, event_time, event_type in events:\n",
      "    if user_id != current_user:\n",
      "        current_user = user_id\n",
      "        session_start = event_time\n",
      "        sessions[user_id] = 1\n",
      "    else:\n",
      "        if event_time - session_start > timedelta(minutes=30):\n",
      "            sessions[user_id] += 1\n",
      "        session_start = event_time\n",
      "\n",
      "print(sessions)\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " {1: 1, 2: 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    \"Parse this CSV string and compute the average of the 'latency_ms' column:\\n\\nts,latency_ms\\n1,120\\n2,110\\n3,130\\n4,90\\n\",\n",
    "    \"Implement rolling z-score anomaly score for this list and print the top 3 most anomalous points: [10,11,9,10,10,200,11,10,9,10]\",\n",
    "    \"Given a list of (user_id, event_time, event_type), compute per-user session counts (30-min gap) and print a dict.\"\n",
    "]\n",
    "\n",
    "for t in tasks:\n",
    "    print('\\n' + '='*80)\n",
    "    print('TASK:', t)\n",
    "    out = run_task(t)\n",
    "    print('OK:', out['last_run']['ok'])\n",
    "    print('STDOUT:\\n', out['last_run']['stdout'])\n",
    "    if not out['last_run']['ok']:\n",
    "        print('STDERR:\\n', out['last_run']['stderr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d53e9",
   "metadata": {},
   "source": [
    "## 3a) Advanced: tighten/loosen execution policy\n",
    "\n",
    "In `tools.py`, you can change:\n",
    "- timeout\n",
    "- banned patterns\n",
    "\n",
    "For meetup safety, keep it restrictive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "research_agent_intro",
   "metadata": {},
   "source": [
    "## 4) Applied Exercise: Research Agent\n",
    "\n",
    "Unlike the code-execution agent, this agent:\n",
    "- Plans multi-step searches\n",
    "- Gathers information from the web via Tavily\n",
    "- Synthesizes findings into a structured report\n",
    "\n",
    "**Use case:** competitive intelligence, market research, due diligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "research_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESEARCH QUESTION:\n",
      "What are the top 3 AI chip companies in 2024 and what's their competitive advantage?\n",
      "\n",
      "\n",
      "============================================================\n",
      "PLANNED QUERIES:\n",
      "  1. top AI chip companies 2024 competitive advantage\n",
      "  2. leading AI chip manufacturers 2024 market position\n",
      "  3. AI chip industry leaders 2024 technology comparison\n",
      "============================================================\n",
      "\n",
      "üîç Searching: top AI chip companies 2024 competitive advantage\n",
      "   ‚Üí Found 3 sources\n",
      "üîç Searching: leading AI chip manufacturers 2024 market position\n",
      "   ‚Üí Found 3 sources\n",
      "üîç Searching: AI chip industry leaders 2024 technology comparison\n",
      "   ‚Üí Found 3 sources\n",
      "\n",
      "‚úì Collected 9 total sources\n",
      "\n",
      "\n",
      "============================================================\n",
      "FINAL REPORT:\n",
      "============================================================\n",
      "**Executive Summary**\n",
      "NVIDIA, AMD, and Google (Alphabet) are the top three AI chip companies in 2024, each leveraging distinct competitive advantages in performance, cost-effectiveness, and specialized architectures. NVIDIA dominates with powerful GPUs for AI training and inference, AMD offers cost-effective alternatives, and Google leads in custom AI accelerators for its ecosystem.\n",
      "\n",
      "**Key Findings**\n",
      "- NVIDIA maintains its strong position in the AI chip market in 2024 due to its powerful GPUs that excel in machine learning tasks, with successful flagship chips like the DGX‚Ñ¢ A100 and H100 designed for AI training and inference in data centers [3][5].\n",
      "- AMD positions itself as a cost-effective and high-performance competitor, driving innovation in chip architecture and software optimization to challenge NVIDIA's dominance [4].\n",
      "- Google (Alphabet) is a key player with its custom AI accelerators, particularly the Tensor Processing Units (TPUs), which are optimized for its cloud and AI services, giving it a competitive edge in specialized applications [4].\n",
      "- The AI chip market is highly competitive, with companies like Amazon, Intel, and Qualcomm also contributing to innovation, but NVIDIA, AMD, and Google lead in market share and technological advancements [1][4][7].\n",
      "- Increased R&D spending by major AI chip makers like NVIDIA and AMD has resulted in more efficient and powerful chips tailored for AI workloads [9].\n",
      "\n",
      "**Conclusion**\n",
      "NVIDIA, AMD, and Google are the top AI chip companies in 2024, each excelling in different areas: NVIDIA in performance, AMD in cost-effectiveness, and Google in specialized AI accelerators. Their competitive advantages stem from continuous innovation and tailored solutions for AI applications.\n"
     ]
    }
   ],
   "source": [
    "from research_agent import run_research\n",
    "\n",
    "question = \"What are the top 3 AI chip companies in 2024 and what's their competitive advantage?\"\n",
    "\n",
    "print(f\"RESEARCH QUESTION:\\n{question}\\n\")\n",
    "\n",
    "result = run_research(question)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL REPORT:\")\n",
    "print(\"=\"*60)\n",
    "print(result[\"report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21269bc7",
   "metadata": {},
   "source": [
    "## 5) Optional: make it multi-agent\n",
    "\n",
    "You can extend `agent_lib.py` into multiple agents:\n",
    "- planner\n",
    "- coder\n",
    "- executor\n",
    "- verifier\n",
    "\n",
    "LangGraph makes these edges explicit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e2e7a-cb87-4ccf-9f22-5c8e7380ad84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
