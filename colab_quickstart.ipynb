{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH0_Yd7ef5se"
      },
      "source": [
        "# Dallas Agent Workshop - Colab Quickstart\n",
        "\n",
        "This notebook runs the workshop repo in Google Colab.\n",
        "\n",
        "Steps:\n",
        "1. Clone the repo + install dependencies\n",
        "2. Set `OPENROUTER_API_KEY` (and optionally `TAVILY_API_KEY`)\n",
        "3. Run the preflight + demo calls\n"
      ],
      "id": "zH0_Yd7ef5se"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79zEZUxif5sg"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "- 5:30 - Check-in, food, networking (30)\n",
        "- 6:00 - Why Agents? (Motivation & Framing) (5)\n",
        "- 6:05 - Core Concepts & Architectures (5)\n",
        "- 6:10 - Setup & Environment (30)\n",
        "- 6:40 - Live Code Walkthrough (20)\n",
        "- 7:00 - Hands-On Build Session (40)\n",
        "- 7:40 - Engineering Discipline for Agents (10)\n",
        "- 7:50 - Next: Virtual sessions, submitting PRs (10)\n",
        "- 8:00 - Curated Resources\n"
      ],
      "id": "79zEZUxif5sg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OcVvIXEf5sg"
      },
      "source": [
        "## Why Agents? (Motivation & Framing)\n",
        "\n",
        "An agent is a loop that can **plan**, **use tools**, and **iterate** toward a goal. In this workshop, the agent can:\n",
        "- Write Python code\n",
        "- Execute it in a controlled way\n",
        "- Read the result (stdout/stderr) and try again\n",
        "\n",
        "Why this matters: lots of real work is not a single prompt. It needs multi-step problem solving, verification, and guardrails.\n"
      ],
      "id": "5OcVvIXEf5sg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBK2llI6f5sg"
      },
      "source": [
        "## Core Concepts & Architectures\n",
        "\n",
        "We will use a simple LangGraph workflow that looks like:\n",
        "\n",
        "`plan -> exec -> (fix -> exec)* -> finish`\n",
        "\n",
        "Key ideas:\n",
        "- **State**: the data that flows between steps (task, generated code, last run result).\n",
        "- **Tools**: the controlled actions the agent can take (here: running Python; for research: web search).\n",
        "- **Guardrails**: constraints that keep the agent safe/reliable (timeouts, blocked imports, \"must print\" requirement).\n",
        "- **Evaluation mindset**: make the agent produce observable outputs so you can debug quickly (stdout, logs, reproducible steps).\n",
        "\n",
        "During the live walkthrough, we will inspect `agent_lib.py` and connect each node to what you see on screen.\n"
      ],
      "id": "GBK2llI6f5sg"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "guLQtatEf5sh",
        "outputId": "cd02fab8-743b-4a5d-b73b-39e4b2d1ad58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dallas-ai-agent-workshop'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 69 (delta 37), reused 53 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (69/69), 38.23 KiB | 9.56 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "/content/dallas-ai-agent-workshop\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blobfile 3.2.0 requires urllib3>=2, but you have urllib3 1.26.20 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jiankunliu-ai/dallas-ai-agent-workshop.git\n",
        "%cd dallas-ai-agent-workshop\n",
        "!pip -q install -r requirements.txt\n"
      ],
      "id": "guLQtatEf5sh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mckBTSvgf5sh"
      },
      "source": [
        "## Set API Keys\n",
        "\n",
        "Use Colab's prompt to avoid hardcoding secrets into the notebook.\n",
        "\n",
        "If you get a 401 later, restart the runtime and rerun this cell.\n"
      ],
      "id": "mckBTSvgf5sh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U6sOqRgf5sh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# openrouter_key = getpass('OPENROUTER_API_KEY: ').strip()\n",
        "# if not openrouter_key:\n",
        "#     raise RuntimeError('OPENROUTER_API_KEY is required')\n",
        "\n",
        "os.environ['OPENROUTER_API_KEY'] = openrouter_key\n",
        "os.environ['OPENROUTER_MODEL'] = 'arcee-ai/trinity-large-preview:free'\n",
        "\n",
        "# tavily_key = getpass('TAVILY_API_KEY (optional, press enter to skip): ').strip()\n",
        "# if tavily_key:\n",
        "  os.environ['TAVILY_API_KEY'] = tavily_key\n"
      ],
      "id": "4U6sOqRgf5sh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOxcdthMf5si"
      },
      "outputs": [],
      "source": [
        "!python test_model.py\n"
      ],
      "id": "FOxcdthMf5si"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYSzx04f5si"
      },
      "source": [
        "## 1) Sanity check: run the Python execution tool\n",
        "\n",
        "The workshop uses a controlled Python execution tool (timeouts + basic safety blocks).\n",
        "This cell verifies that it runs and returns stdout/stderr as expected.\n"
      ],
      "id": "aXYSzx04f5si"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e7aouJef5si"
      },
      "outputs": [],
      "source": [
        "from tools import run_python\n",
        "\n",
        "run_python(\"print('hello from sandbox')\")\n"
      ],
      "id": "6e7aouJef5si"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uEJd80Xf5si"
      },
      "source": [
        "## 2) Run a single agent task\n",
        "\n",
        "This is the core loop: plan -> code -> exec -> fix (repeat) -> finish.\n"
      ],
      "id": "1uEJd80Xf5si"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W2N3AYWf5si"
      },
      "outputs": [],
      "source": [
        "from agent_lib import run_task\n",
        "\n",
        "task = \"Write a Python function to compute Fibonacci(n) efficiently and print Fibonacci(35).\"\n",
        "result = run_task(task)\n",
        "\n",
        "result['last_run']\n"
      ],
      "id": "9W2N3AYWf5si"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgs0TYyLf5si"
      },
      "source": [
        "## 3) Workshop exercises\n",
        "\n",
        "Try a few tasks that require parsing, statistics, and basic data logic.\n"
      ],
      "id": "Dgs0TYyLf5si"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8HjozgPf5si"
      },
      "outputs": [],
      "source": [
        "from agent_lib import run_task\n",
        "\n",
        "tasks = [\n",
        "    \"Parse this CSV string and compute the average of the 'latency_ms' column:\\n\\nts,latency_ms\\n1,120\\n2,110\\n3,130\\n4,90\\n\",\n",
        "    \"Implement rolling z-score anomaly score for this list and print the top 3 most anomalous points: [10,11,9,10,10,200,11,10,9,10]\",\n",
        "    \"Given a list of (user_id, event_time, event_type), compute per-user session counts (30-min gap) and print a dict.\"\n",
        "]\n",
        "\n",
        "for t in tasks:\n",
        "    print('\\n' + '='*80)\n",
        "    print('TASK:', t)\n",
        "    out = run_task(t)\n",
        "    print('OK:', out['last_run']['ok'])\n",
        "    print('STDOUT:\\n', out['last_run']['stdout'])\n",
        "    if not out['last_run']['ok']:\n",
        "        print('STDERR:\\n', out['last_run']['stderr'])\n"
      ],
      "id": "p8HjozgPf5si"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vejd0KnIf5si"
      },
      "source": [
        "## 3a) Advanced: tighten/loosen execution policy\n",
        "\n",
        "Optional: inspect `tools.py` to see what imports/calls are blocked, and discuss tradeoffs.\n",
        "In a real product you would add stronger sandboxing, allowlists, and auditing.\n"
      ],
      "id": "Vejd0KnIf5si"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL5mMfe-f5si"
      },
      "source": [
        "## 4) Applied Exercise: Research Agent\n",
        "\n",
        "Unlike the code-execution agent, this agent:\n",
        "\n",
        "- Plans multi-step searches\n",
        "- Gathers information from the web via Tavily\n",
        "- Synthesizes findings into a structured report\n",
        "\n",
        "Use case: competitive intelligence, market research, due diligence\n"
      ],
      "id": "AL5mMfe-f5si"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puUCxPerf5si"
      },
      "outputs": [],
      "source": [
        "from research_agent import run_research\n",
        "\n",
        "question = \"What are the top 3 AI chip companies in 2024 and what's their competitive advantage?\"\n",
        "\n",
        "print(f\"RESEARCH QUESTION:\\n{question}\\n\")\n",
        "\n",
        "result = run_research(question)\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('FINAL REPORT:')\n",
        "print('='*60)\n",
        "print(result[\"report\"])\n"
      ],
      "id": "puUCxPerf5si"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs2AY2fuf5sj"
      },
      "source": [
        "## 5) Engineering Discipline for Agents\n",
        "\n",
        "Agents feel \"magical\" until they fail. The fastest way to make them reliable is good engineering hygiene:\n",
        "\n",
        "- **State management**: write down what the agent knows (inputs/outputs) and pass it explicitly.\n",
        "- **Context management**: keep prompts short and structured; include only what is necessary; summarize when needed.\n",
        "- **Memory (optional)**: decide what should persist across runs (none vs. per-session vs. long-term).\n",
        "- **Token budgeting**: constrain output formats; avoid dumping large logs or huge documents into the model.\n",
        "- **Governance & safety**: limit tools and permissions; log tool calls; treat credentials carefully; assume untrusted outputs.\n",
        "\n",
        "In this repo, we keep things workshop-safe by forcing observable stdout, logging generated code, adding timeouts, and blocking risky Python calls.\n"
      ],
      "id": "Cs2AY2fuf5sj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNrAxi_3f5sj"
      },
      "source": [
        "## 7) Next: Virtual sessions + Submitting PRs\n",
        "\n",
        "Stretch goals (great for follow-up sessions):\n",
        "- Add more tools (file I/O, data APIs) with careful safety boundaries\n",
        "- Turn the workflow into multiple collaborating agents (planner + specialists)\n",
        "- Add lightweight evaluations (golden tests, regression prompts, success criteria)\n",
        "\n",
        "If you improve the workshop materials, please open a PR against this repo.\n"
      ],
      "id": "uNrAxi_3f5sj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyouO_z5f5sj"
      },
      "source": [
        "## 8) Curated Resources\n",
        "\n",
        "- Prompting best practices (Claude): https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices\n",
        "- LangGraph docs: https://langchain-ai.github.io/langgraph/\n",
        "- OpenRouter docs: https://openrouter.ai/docs\n",
        "\n",
        "Tip: when learning, keep a small set of repeatable test prompts (like `2+2`, Fibonacci, CSV parse) to validate changes quickly.\n"
      ],
      "id": "ZyouO_z5f5sj"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}